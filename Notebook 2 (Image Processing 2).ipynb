{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63c60a6b",
   "metadata": {},
   "source": [
    "<img src=\"Image 4.png\" width=\"1050\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0bd460",
   "metadata": {},
   "source": [
    "Data Pre-Porcessing is a vital step in any Machine Learning or Deep Learning technique. This mining technique which is used to transform the raw data in a useful and efficient format.\n",
    "In this case we are dealing with Image Data where a model to understand and differentiate an image, certain Pre-Processing techniques are implemented. Such approach helps in efficient Model Building.\n",
    "\n",
    "The Model will be trained on such Pre-Processed data which can enhance the understanding of type and features of an image.\n",
    "In this process, the data are made to Pre-Process under various factors and conditions which helps the model to classify the given image being \"Accept\" or \"Reject\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cd2b00",
   "metadata": {},
   "source": [
    "## 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c9e81ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug as ia                                                     # imgaug uses matplotlib backend for displaying images\n",
    "ia.seed(1)\n",
    "%matplotlib inline\n",
    "import imageio                                                          # Image Input/Output Reader\n",
    "import pandas as pd                                                     # Importing Pandas\n",
    "import numpy as np                                                      # Importing Numpy\n",
    "import os                                                               # Importing Operating System\n",
    "import glob                                                             # Used to return all file paths that match a specific pattern\n",
    "from PIL import Image, ImageEnhance                                     # Using Pillow, import Image and Image Enhancer (To enhance the quality of an Image)\n",
    "from skimage import exposure                                            # Implemented for Histogram Equalization\n",
    "import matplotlib.pyplot as plt                                         # Importing Matplotlib for Visualization \n",
    "import cv2                                                              # Importing Computer Vision Tool\n",
    " \n",
    "img_width, img_height = 256, 256\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [15,8]                                 # Setting a standard figure size of (15,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418a33d3",
   "metadata": {},
   "source": [
    "## 2. Accessing Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b56f7c",
   "metadata": {},
   "source": [
    "Below the paths of both Cropped images of Accept and Reject are accessed through os.path.join.\n",
    "\n",
    "The Cropped images are accessed for the analysis which will be further used for Image Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5015bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a New Directory for Accept Images\n",
    "\n",
    "CROPPED_PATH = os.path.join('reinforced_images4','Accept_Images')\n",
    "# C:\\Users\\nabhishe\\MITC Project\n",
    "\n",
    "if not os.path.exists(CROPPED_PATH):\n",
    "    !mkdir {CROPPED_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d80871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a New Directory for Reject Images\n",
    "\n",
    "CROPPED_PATH = os.path.join('reinforced_images4','Reject_Images')\n",
    "# C:\\Users\\nabhishe\\MITC Project\n",
    "\n",
    "if not os.path.exists(CROPPED_PATH):\n",
    "    !mkdir {CROPPED_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc7bf03",
   "metadata": {},
   "source": [
    "#### Accept & Reject Image color distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20eb519",
   "metadata": {},
   "source": [
    "Below shows a basic idea of how images are classified based on the coating.\n",
    "\n",
    "- The images are read from the directory and converted from BGR to RGB.\n",
    "- An estimation is established by setting a threshold. In this case a threshold of 140 is set (taking a grayscale range from 0 to 255).\n",
    "- A condition given if mean of an image is greater than 140 [ mean(img) > 140 ]\n",
    "- If this condition satisfies, the pattern/Coating of an image is considered \"Dark\" else \"Bright\"\n",
    "\n",
    "The above analysis helps in understanding the pixel distribution based on different ways a plate is coated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f65268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reject Images\n",
    "images = glob.glob(\"C:\\\\Users\\\\nabhishe\\\\MITC_Project\\\\cropped_images1\\\\Reject_Cropped\\\\*.jpg\")\n",
    "for image in images:\n",
    "    f = imageio.imread(image, as_gray=True)\n",
    "    img1 = cv2.imread(image)\n",
    "    plt.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    def img_estim(img, thrshld):\n",
    "        is_light = np.mean(img) > thrshld\n",
    "        return 'light' if is_light else 'dark'\n",
    "\n",
    "    print(img_estim(f, 140))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b9b289",
   "metadata": {},
   "source": [
    "<img src=\"Image 5.png\" width=\"750\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057b9ede",
   "metadata": {},
   "source": [
    "A similar approach is taken for Accept Images for understanding the color coating distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e13a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accept Images\n",
    "images = glob.glob(\"C:\\\\Users\\\\nabhishe\\\\MITC_Project\\\\cropped_images1\\\\Accept_Cropped\\\\*.jpg\")\n",
    "for image in images:\n",
    "    f = imageio.imread(image, as_gray=True)\n",
    "    img1 = cv2.imread(image)\n",
    "    plt.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    def img_estim(img, thrshld):\n",
    "        is_light = np.mean(img) > thrshld\n",
    "        return 'light' if is_light else 'dark'\n",
    "\n",
    "    print(img_estim(f, 140))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3b6d0d",
   "metadata": {},
   "source": [
    "<img src=\"Image 6.png\" width=\"750\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1999912",
   "metadata": {},
   "source": [
    "## 3. Image Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b236ac22",
   "metadata": {},
   "source": [
    "Image Pre-Processing is a vital step for any Model Building. In order for a model to understand the features and using that to classify, we go with Pre-Processing.\n",
    "In this stage the images are divided into 4 categories. \n",
    "\n",
    "1) Dark Reject Images\n",
    "\n",
    "2) Bright Reject Images\n",
    "\n",
    "3) Dark Accept Images\n",
    "\n",
    "4) Bright Accept Images\n",
    "\n",
    "The above step is carried out due to variations in Coating of plate. In order for a model to undertand and classify whether a given image is \"Accept\" or \"Reject\" irrespective of any type of coating, the above 4 methods are carried.\n",
    "\n",
    "This step handles biasing of image irrespective of any type of Coating and can enhance the performance of Neural Network Model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a92e18",
   "metadata": {},
   "source": [
    "### Reject Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cce3c27",
   "metadata": {},
   "source": [
    "#### Dark Reject Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfc07c1",
   "metadata": {},
   "source": [
    "The below implementation helps in understanding the methods taken to handle Dark Reject Images coatings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a011fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# considering a Dark Reject image\n",
    "\n",
    "path = 'C:\\\\Users\\\\nabhishe\\\\MITC_Project\\\\cropped_images1\\\\Reject_Cropped\\\\'\n",
    "for f in os.listdir(path):\n",
    "    if f.endswith(\".jpg\"):\n",
    "        image = plt.imread('C:\\\\Users\\\\nabhishe\\\\MITC_Project\\\\cropped_images1\\\\Reject_Cropped\\\\'+str(f))\n",
    "        fn, fext = os.path.splitext(f)\n",
    "        #enhancer = ImageEnhance.Brightness(image)\n",
    "        #new_image = enhancer.enhance(1.5)\n",
    "        threshold = 140\n",
    "        if np.mean(image) < threshold:\n",
    "            adapthist_image = exposure.equalize_hist(image)\n",
    "            im = Image.fromarray((adapthist_image*255).astype(np.uint8)) \n",
    "            images = im.convert(mode = 'L')  \n",
    "            image_np = np.array(images)\n",
    "            sharp = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])      \n",
    "            custom_img = cv2.filter2D(image_np,-1,sharp)\n",
    "            contrast = cv2.convertScaleAbs(custom_img, alpha=1, beta=50)\n",
    "            blurred = cv2.GaussianBlur(contrast, (3, 3), 0)\n",
    "            thresh = cv2.threshold(blurred, 120, 255, cv2.THRESH_BINARY)[1]\n",
    "            thresh = cv2.erode(thresh, None, iterations=7)\n",
    "            thresh = cv2.dilate(thresh, None, iterations=3)\n",
    "            cv2.imwrite(\"C:\\\\Users\\\\nabhishe\\\\MITC_Project\\\\reinforced_images4\\\\Reject_Images\\\\{}.{}\".format(fn, fext), thresh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ffbca7",
   "metadata": {},
   "source": [
    "* <b>Implementation</b> : \n",
    "\n",
    "The paths are accessed for the Cropped Reject Images using os.listdir\n",
    "\n",
    "The images are read from the directory and a condition is set at 140. This condition is set after various tries of ranges based on Grayscale (0 to 255).\n",
    "\n",
    "- Mean of an image is considered and checked if it is less than <b>threshold (140)</b>\n",
    "- <b>Adaptive Equalized</b> Threshold is used to check the distribution of pixel across the graph.\n",
    "- In this case exposure.equalize_hist is implemented to uniform distribution of pixel across the range\n",
    "- The input image is then converted into an array with a type of <b>8-bit</b> using (.astype).\n",
    "- Further the image is converted into <b>Grayscale</b> using <b>.convert(mode='L')</b>\n",
    "- An Array of resultant Grayscale image is Filtered using <b>Filter2D</b> and sharpening with a Kernel by <b>(3x3)</b> matrix.\n",
    "- <b>ConvertScaleAbs</b> is introduced using cv2 (Computer Vision) and tuning by <b>Alpha and Beta</b>.\n",
    "- This helps in Scaling, computing absolute values and converts the result to 8-bit.\n",
    "- The transformed image is passed into <b>Gaussian Blur</b> where the image is blurred to a contrast set by a user defined Kernel, in this case (3,3)\n",
    "- The Blurred Image is hence Thresholded with <b>THRESH_BINARY</b> and the levels are set with a threshold.\n",
    "- In the above task each pixel values are compared with the threshold and converted into a Binary Image (Black & White).\n",
    "- The final Thresholded image is then iterated over <b>Erosion</b> and <b>Dilation</b> Process.\n",
    "- <b>Erosion</b> and <b>Dilation</b> helps in inceasing or blurring the nature of Pixels.\n",
    "- Erosion increases the depth in those pixel regions where it is necessary for our analysis.\n",
    "- Dilation suppresses those pixel regions into white.\n",
    "\n",
    "<b>Erosion and Dilation helps in fetching those pixels suitable for our Analysis by extracting those Bit mark regions in Black and retaining others in White</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c140a1a",
   "metadata": {},
   "source": [
    "#### Bright Reject Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4a3432",
   "metadata": {},
   "source": [
    "The similar case of implementation can be used for Bright Reject Images where a Mean of an image is greater than 140 <b>[ mean(img) > 140]</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6feaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################\n",
    "\n",
    "# considering a bright Reject image                                      \n",
    "\n",
    "path = 'C:\\\\Users\\\\nabhishe\\\\MITC_Project\\\\cropped_images\\\\Reject_Cropped\\\\'\n",
    "for f in os.listdir(path):\n",
    "    if f.endswith(\".jpg\"):\n",
    "        image = Image.open('C:\\\\Users\\\\nabhishe\\\\MITC_Project\\\\cropped_images\\\\Reject_Cropped\\\\'+str(f))\n",
    "        #enhancer = ImageEnhance.Brightness(image)\n",
    "        #im_output = enhancer.enhance(1.5)\n",
    "        fn, fext = os.path.splitext(f)\n",
    "        threshold = 140\n",
    "        if np.mean(image) > threshold:\n",
    "            images = image.convert(mode = 'L')\n",
    "            image_np = np.array(images)\n",
    "            sharp = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])       # sharpening the image\n",
    "            custom_img = cv2.filter2D(image_np,-1,sharp)\n",
    "            contrast = cv2.convertScaleAbs(custom_img, alpha=1, beta=60)\n",
    "            blurred = cv2.GaussianBlur(contrast, (7, 7), 0)\n",
    "            thresh = cv2.threshold(blurred, 180, 255, cv2.THRESH_BINARY)[1]\n",
    "            thresh = cv2.erode(thresh, None, iterations=7)\n",
    "            thresh = cv2.dilate(thresh, None, iterations=3)\n",
    "            #thresh.save(\"C:\\\\Users\\\\nabhishe\\\\MITC_Project\\\\reinforced_images\\\\Reject_images\\\\{}_bw.{}\".format(fn, fext))\n",
    "            cv2.imwrite(\"C:\\\\Users\\\\nabhishe\\\\MITC_Project\\\\reinforced_images4\\\\Reject_Images\\\\{}.{}\".format(fn, fext), thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc79c610",
   "metadata": {},
   "source": [
    "* Implementation :\n",
    "    \n",
    "Certain changes are experimented and observed compared to Bright Reject Images. The following are listed below:\n",
    "\n",
    "- <b>Adaptive Equalized Histogram</b> is not implemented for this analysis.\n",
    "- The mean of the Image is taken and checked whether it is greater than <b>threshold (140)</b>.\n",
    "- If the conditions passes, the image is converted into a Grayscale orientation and made it into an Array.\n",
    "- After adjusting the contrast using <b>ConvertScaleAbs</b>, a Gaussian Blur with kernel <b>(7,7)</b> is used for Image Blurring.\n",
    "- Since we are dealing with Bright Images, the pixel values of the range <b>180</b> and <b>255</b> are compared with the <b>threshold (140)</b>.\n",
    "- The resultant image is tuned with <b>Erosion</b> and <b>Dilation</b> and stored in a Directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f090eb95",
   "metadata": {},
   "source": [
    "### Accept Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ed0d59",
   "metadata": {},
   "source": [
    "The Pre-Processing techniques used in Accept Images are dealt with same implementations used for Reject Images.\n",
    "\n",
    "In this case Accept Images are divided into Dark Accept and Bright Accept based on the Coating. The implementations are carried out in the similar manner as it was dealt with Reject Images.\n",
    "\n",
    "The Pre-Processing steps taken for both type of Coating are as shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29050063",
   "metadata": {},
   "source": [
    "#### Dark Accept Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032f4b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################\n",
    "\n",
    "# considering a Dark Accept image                                      \n",
    "\n",
    "path = 'C:\\\\Users\\\\nabhishe\\\\MITC_Project\\\\cropped_images\\\\Accept_Cropped\\\\'\n",
    "for f in os.listdir(path):\n",
    "    if f.endswith(\".jpg\"):\n",
    "        image = Image.open('C:\\\\Users\\\\nabhishe\\\\MITC_Project\\\\cropped_images\\\\Accept_Cropped\\\\'+str(f))\n",
    "        fn, fext = os.path.splitext(f)\n",
    "        threshold = 140\n",
    "        if np.mean(image) < threshold: \n",
    "            images = image.convert(mode = 'L')\n",
    "            image_np = np.array(images)\n",
    "            sharp = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])       # sharpening the image\n",
    "            custom_img = cv2.filter2D(image_np,-1,sharp)\n",
    "            contrast = cv2.convertScaleAbs(custom_img, alpha=1, beta=110)\n",
    "            blurred = cv2.GaussianBlur(contrast, (5, 5), 0)\n",
    "            thresh = cv2.threshold(blurred, 200, 255, cv2.THRESH_BINARY)[1]\n",
    "            thresh = cv2.erode(thresh, None, iterations=5)\n",
    "            thresh = cv2.dilate(thresh, None, iterations=5)\n",
    "            #thresh.save(\"C:\\\\Users\\\\nabhishe\\\\MITC_Project\\\\reinforced_images\\\\Reject_images\\\\{}_bw.{}\".format(fn, fext))\n",
    "            cv2.imwrite(\"C:\\\\Users\\\\nabhishe\\\\MITC_Project\\\\reinforced_images4\\\\Accept_Images\\\\{}.{}\".format(fn, fext), thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec352aba",
   "metadata": {},
   "source": [
    "#### Bright Accept Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc7a8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################\n",
    "\n",
    "# considering a bright Accept image                                       (194 images)\n",
    "\n",
    "path = 'C:\\\\Users\\\\nabhishe\\\\MITC_Project\\\\cropped_images\\\\Accept_Cropped\\\\'\n",
    "for f in os.listdir(path):\n",
    "    if f.endswith(\".jpg\"):\n",
    "        image = Image.open('C:\\\\Users\\\\nabhishe\\\\MITC_Project\\\\cropped_images\\\\Accept_Cropped\\\\'+str(f))\n",
    "        fn, fext = os.path.splitext(f)\n",
    "        threshold = 140\n",
    "        if np.mean(image) > threshold:\n",
    "            images = image.convert(mode = 'L')\n",
    "            image_np = np.array(images)\n",
    "            sharp = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])       # sharpening the image\n",
    "            custom_img = cv2.filter2D(image_np,-1,sharp)\n",
    "            contrast = cv2.convertScaleAbs(custom_img, alpha=1, beta=100)\n",
    "            blurred = cv2.GaussianBlur(contrast, (7, 7), 0)\n",
    "            thresh = cv2.threshold(blurred, 225, 255, cv2.THRESH_BINARY)[1]\n",
    "            thresh = cv2.erode(thresh, None, iterations=3)\n",
    "            thresh = cv2.dilate(thresh, None, iterations=5)\n",
    "            #thresh.save(\"C:\\\\Users\\\\nabhishe\\\\MITC_Project\\\\reinforced_images\\\\Reject_images\\\\{}_bw.{}\".format(fn, fext))\n",
    "            cv2.imwrite(\"C:\\\\Users\\\\nabhishe\\\\MITC_Project\\\\reinforced_images4\\\\Accept_Images\\\\{}.{}\".format(fn, fext), thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303549ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa8b98b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
