{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c9e81ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import imgaug as ia\n",
    "ia.seed(1)\n",
    "# imgaug uses matplotlib backend for displaying images\n",
    "%matplotlib inline\n",
    "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
    "from imgaug import augmenters as iaa \n",
    "# imageio library will be used for image input/output\n",
    "import imageio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "# this library is needed to read XML files for converting it into CSV\n",
    "import xml.etree.ElementTree as ET\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from PIL import Image, ImageEnhance\n",
    "\n",
    "# Importing all necessary libraries\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    " \n",
    "img_width, img_height = 256, 256\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [15,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f9d22da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "#from pyimagesearch import config\n",
    "from skimage import data, exposure\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from skimage import transform\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import mimetypes\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5015bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a New Directory for Accept Images\n",
    "\n",
    "CROPPED_PATH = os.path.join('reinforced_images4','Accept_Images')\n",
    "# C:\\Users\\nabhishe\\MITC Project\n",
    "\n",
    "if not os.path.exists(CROPPED_PATH):\n",
    "    !mkdir {CROPPED_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d80871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a New Directory for Reject Images\n",
    "\n",
    "CROPPED_PATH = os.path.join('reinforced_images4','Reject_Images')\n",
    "# C:\\Users\\nabhishe\\MITC Project\n",
    "\n",
    "if not os.path.exists(CROPPED_PATH):\n",
    "    !mkdir {CROPPED_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f65268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reject Images\n",
    "images = glob.glob(\"C:\\\\Users\\\\nabhishe\\\\MITC_Project\\\\cropped_images1\\\\Reject_Cropped\\\\*.jpg\")\n",
    "for image in images:\n",
    "    f = imageio.imread(image, as_gray=True)\n",
    "    img1 = cv2.imread(image)\n",
    "    plt.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    def img_estim(img, thrshld):\n",
    "        is_light = np.mean(img) > thrshld\n",
    "        return 'light' if is_light else 'dark'\n",
    "\n",
    "    print(img_estim(f, 140))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e13a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accept Images\n",
    "images = glob.glob(\"C:\\\\Users\\\\nabhishe\\\\MITC_Project\\\\cropped_images1\\\\Accept_Cropped\\\\*.jpg\")\n",
    "for image in images:\n",
    "    f = imageio.imread(image, as_gray=True)\n",
    "    img1 = cv2.imread(image)\n",
    "    plt.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    def img_estim(img, thrshld):\n",
    "        is_light = np.mean(img) > thrshld\n",
    "        return 'light' if is_light else 'dark'\n",
    "\n",
    "    print(img_estim(f, 140))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013aa103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09a92e18",
   "metadata": {},
   "source": [
    "### Reject Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cce3c27",
   "metadata": {},
   "source": [
    "#### Dark Reject Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a011fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################\n",
    "\n",
    "# considering a Dark Reject image\n",
    "\n",
    "path = 'C:\\\\Users\\\\nabhishe\\\\MITC_Project\\\\cropped_images1\\\\Reject_Cropped\\\\'\n",
    "for f in os.listdir(path):\n",
    "    if f.endswith(\".jpg\"):\n",
    "        image = plt.imread('C:\\\\Users\\\\nabhishe\\\\MITC_Project\\\\cropped_images1\\\\Reject_Cropped\\\\'+str(f))\n",
    "        fn, fext = os.path.splitext(f)\n",
    "        #enhancer = ImageEnhance.Brightness(image)\n",
    "        #new_image = enhancer.enhance(1.5)\n",
    "        threshold = 140\n",
    "        if np.mean(image) < threshold:\n",
    "            adapthist_image = exposure.equalize_hist(image)\n",
    "            im = Image.fromarray((adapthist_image*255).astype(np.uint8)) \n",
    "            images = im.convert(mode = 'L')  \n",
    "            image_np = np.array(images)\n",
    "            sharp = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])       # sharpening the image\n",
    "            custom_img=cv2.filter2D(image_np,-1,sharp)\n",
    "            contrast = cv2.convertScaleAbs(custom_img, alpha=1, beta=50)\n",
    "            blurred = cv2.GaussianBlur(contrast, (3, 3), 0)\n",
    "            thresh = cv2.threshold(blurred, 120, 255, cv2.THRESH_BINARY)[1]\n",
    "            thresh = cv2.erode(thresh, None, iterations=7)\n",
    "            thresh = cv2.dilate(thresh, None, iterations=3)\n",
    "            #thresh.save(\"C:\\\\Users\\\\nabhishe\\\\MITC_Project\\\\reinforced_images\\\\Reject_images\\\\{}_bw.{}\".format(fn, fext))\n",
    "            cv2.imwrite(\"C:\\\\Users\\\\nabhishe\\\\MITC_Project\\\\reinforced_images4\\\\Reject_Images\\\\{}.{}\".format(fn, fext), thresh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c140a1a",
   "metadata": {},
   "source": [
    "#### Bright Reject Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6feaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################\n",
    "\n",
    "# considering a bright Reject image                                      \n",
    "\n",
    "path = 'C:\\\\Users\\\\nabhishe\\\\MITC_Project\\\\cropped_images\\\\Reject_Cropped\\\\'\n",
    "for f in os.listdir(path):\n",
    "    if f.endswith(\".jpg\"):\n",
    "        image = Image.open('C:\\\\Users\\\\nabhishe\\\\MITC_Project\\\\cropped_images\\\\Reject_Cropped\\\\'+str(f))\n",
    "        #enhancer = ImageEnhance.Brightness(image)\n",
    "        #im_output = enhancer.enhance(1.5)\n",
    "        fn, fext = os.path.splitext(f)\n",
    "        threshold = 140\n",
    "        if np.mean(image) > threshold:\n",
    "            images = image.convert(mode = 'L')\n",
    "            image_np = np.array(images)\n",
    "            sharp = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])       # sharpening the image\n",
    "            custom_img=cv2.filter2D(image_np,-1,sharp)\n",
    "            contrast = cv2.convertScaleAbs(custom_img, alpha=1, beta=60)\n",
    "            blurred = cv2.GaussianBlur(contrast, (7, 7), 0)\n",
    "            thresh = cv2.threshold(blurred, 180, 255, cv2.THRESH_BINARY)[1]\n",
    "            thresh = cv2.erode(thresh, None, iterations=7)\n",
    "            thresh = cv2.dilate(thresh, None, iterations=3)\n",
    "            #thresh.save(\"C:\\\\Users\\\\nabhishe\\\\MITC_Project\\\\reinforced_images\\\\Reject_images\\\\{}_bw.{}\".format(fn, fext))\n",
    "            cv2.imwrite(\"C:\\\\Users\\\\nabhishe\\\\MITC_Project\\\\reinforced_images4\\\\Reject_Images\\\\{}.{}\".format(fn, fext), thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a773a5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f090eb95",
   "metadata": {},
   "source": [
    "### Accept Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29050063",
   "metadata": {},
   "source": [
    "#### Dark Accept Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032f4b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################\n",
    "\n",
    "# considering a Dark Accept image                                      \n",
    "\n",
    "path = 'C:\\\\Users\\\\nabhishe\\\\MITC_Project\\\\cropped_images\\\\Accept_Cropped\\\\'\n",
    "for f in os.listdir(path):\n",
    "    if f.endswith(\".jpg\"):\n",
    "        image = Image.open('C:\\\\Users\\\\nabhishe\\\\MITC_Project\\\\cropped_images\\\\Accept_Cropped\\\\'+str(f))\n",
    "        fn, fext = os.path.splitext(f)\n",
    "        threshold = 140\n",
    "        if np.mean(image) < threshold: \n",
    "            images = image.convert(mode = 'L')\n",
    "            image_np = np.array(images)\n",
    "            sharp = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])       # sharpening the image\n",
    "            custom_img=cv2.filter2D(image_np,-1,sharp)\n",
    "            contrast = cv2.convertScaleAbs(custom_img, alpha=1, beta=110)\n",
    "            blurred = cv2.GaussianBlur(contrast, (5, 5), 0)\n",
    "            thresh = cv2.threshold(blurred, 200, 255, cv2.THRESH_BINARY)[1]\n",
    "            thresh = cv2.erode(thresh, None, iterations=5)\n",
    "            thresh = cv2.dilate(thresh, None, iterations=5)\n",
    "            #thresh.save(\"C:\\\\Users\\\\nabhishe\\\\MITC_Project\\\\reinforced_images\\\\Reject_images\\\\{}_bw.{}\".format(fn, fext))\n",
    "            cv2.imwrite(\"C:\\\\Users\\\\nabhishe\\\\MITC_Project\\\\reinforced_images4\\\\Accept_Images\\\\{}.{}\".format(fn, fext), thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec352aba",
   "metadata": {},
   "source": [
    "#### Bright Accept Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc7a8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################\n",
    "\n",
    "# considering a bright Accept image                                       (194 images)\n",
    "\n",
    "path = 'C:\\\\Users\\\\nabhishe\\\\MITC_Project\\\\cropped_images\\\\Accept_Cropped\\\\'\n",
    "for f in os.listdir(path):\n",
    "    if f.endswith(\".jpg\"):\n",
    "        image = Image.open('C:\\\\Users\\\\nabhishe\\\\MITC_Project\\\\cropped_images\\\\Accept_Cropped\\\\'+str(f))\n",
    "        fn, fext = os.path.splitext(f)\n",
    "        threshold = 140\n",
    "        if np.mean(image) > threshold:\n",
    "            images = image.convert(mode = 'L')\n",
    "            image_np = np.array(images)\n",
    "            sharp = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])       # sharpening the image\n",
    "            custom_img=cv2.filter2D(image_np,-1,sharp)\n",
    "            contrast = cv2.convertScaleAbs(custom_img, alpha=1, beta=100)\n",
    "            blurred = cv2.GaussianBlur(contrast, (7, 7), 0)\n",
    "            thresh = cv2.threshold(blurred, 225, 255, cv2.THRESH_BINARY)[1]\n",
    "            thresh = cv2.erode(thresh, None, iterations=3)\n",
    "            thresh = cv2.dilate(thresh, None, iterations=5)\n",
    "            #thresh.save(\"C:\\\\Users\\\\nabhishe\\\\MITC_Project\\\\reinforced_images\\\\Reject_images\\\\{}_bw.{}\".format(fn, fext))\n",
    "            cv2.imwrite(\"C:\\\\Users\\\\nabhishe\\\\MITC_Project\\\\reinforced_images4\\\\Accept_Images\\\\{}.{}\".format(fn, fext), thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303549ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
